---
title: "1M-Deepfakes Detection Challenge - ACM MM 2024"
date: 2024-03-05T00:06:56+08:00
---

<br>
<div class="row">
  <div>
    <p><center>
        <img class="img-fluid banner-pic" src="https://raw.githubusercontent.com/ControlNet/AV-Deepfake1M/master/assets/teaser.png">
    </center></p>
    <!-- <p><center>
      Full day, <font size="3" color="red"> Oct 2023</font> (Full-day)
    </center></p> -->
  </div>
</div><br>


## Introduction

The tremendous progress in generative AI has made the generation and manipulation of synthetic data easier and
faster than before. To this end, multiple use cases are benefitting from it. The negative aspect of this progress and
wide adoption of generative AI is deepfakes. Audio/image/video of an individual(s) is manipulated using
generative methods without permission from the individual(s). This can make them be shown saying or doing
something, which they may not have done in real. These unethically manipulated videos, popularly known as
deepfakes have wide repercussions and negative effects on society in the form of the deepfakes’ potential in
spreading disinformation and misinformation. Deepfakes unfortunately are used for trolling online as well.
Authentication systems such as video KYC (Know Your Customer) are also not resilient as often face recognition
and verification systems are deceived when high-quality deepfakes are used. To this end, it is important for
platforms and systems to be able to identify if manipulation has been performed on a media. These systems,
which detect and analyse the deepfakes are referred to as deepfakes detectors.

The 1M-Deepfakes Detection Challenge comprises of two sub-tasks:

1. *Deepfake Detection* – Given an audio-visual sample containing a single subject, the task is to identify if the
video is a deepfake or real.

2. *Deepfakes Temporal Localisation* – Given an audio-visual sample containing a single subject, the task is to find
out the frames (time stamps) in which the manipulation is done. The assumption here is that from the perspective
of spreading misinformation.

The dataset used for the two tasks above is the recently proposed AV-Deepfake1M. The database contains
over a million data points, the Train, Validation and Test sets distribution is shown below.

![stats](stats.jpg)

## Important Dates

<table class="table table-striped">
    <tbody>
        <tr>
          <td>Train and validation set release</td>
          <td>March 5, 2024</td>
        </tr>
        <tr>
          <td>Test set release</td>
          <td>TBD</td>
        </tr>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>June 14, 2024</td>
        </tr>
        <tr>
          <td>Final Decision</td>
          <td>July 15, 2024</td>
        </tr>
        <tr>
          <td>Camera-Ready Deadline</td>
          <td>July 29, 2024</td>
        </tr>
    </tbody>
</table>

## Program Schedule

TBD

## Invited Keynote Speakers

TBD

## Organizers

- Zhixi Cai, Monash University
- Abhinav Dhall, Flinders University
- Shreya Ghosh, Curtin University
- Munawar Hayat, Qualcomm/Monash University
- Dimitrios Kollias, Queen Mary University of London
- Kalin Stefanov, Monash University
- Usman Tariq, American University of Sharjah

## Program Committee (To be updated)

TBD

## Contact

- Abhinav Dhall, abhinav.dhall@flinders.edu.au
- Zhixi Cai, zhixi.cai@monash.edu
- Kalin Stefanov, kalin.stefanov@monash.edu
- Shreya Ghosh, shreya.ghosh@curtin.edu.au
 

<style>
    .speaker-pic {
        width: 250px;
        height: 250px;
    }
    .organizer-pic {
        width: 200px;
        height: 200px;
    }
    .uni-name {
        max-width: 200px
    }

    .people-name {
        max-width: 200px;
    } 

    .orgnizer-people-name {
        text-align: center;
    }

    .speaker-pic, .organizer-pic {
        border-radius: 50%;
    }

    .banner-pic {
        width: 900px;
        height: auto;
    }
</style>